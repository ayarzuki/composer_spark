# Composer, Pyspark for word count

1. Create Cloud Composer environment

2. Create a Cloud Storage bucket

3. Defining the workflow

4. Uploading DAG to cloud storage
   ```
   gsutil cp spark_dibimbing.py <DAGs_folder_path>
   ```

5. We use public data and copy to your Cloud Storage bucket
   ```
   public data to your Cloud Storage bucket
   ```

6. The result is word count DAG and save to CSV. This is the result and DAF success prove
<img width="971" alt="Jepretan Layar 2023-10-01 pukul 01 24 17" src="https://github.com/ayarzuki/composer_spark/assets/48020037/d1e064eb-f37b-4a2d-b346-e9de18e32404">

<img width="823" alt="Jepretan Layar 2023-10-01 pukul 01 26 36" src="https://github.com/ayarzuki/composer_spark/assets/48020037/a7ced575-62bb-4249-9190-3756be319b31">
